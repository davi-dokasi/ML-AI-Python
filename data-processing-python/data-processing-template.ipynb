{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORE PKG'S\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>France</td>\n",
       "      <td>44.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>27.0</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spain</td>\n",
       "      <td>38.0</td>\n",
       "      <td>61000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Germany</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>France</td>\n",
       "      <td>35.0</td>\n",
       "      <td>58000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Spain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>France</td>\n",
       "      <td>48.0</td>\n",
       "      <td>79000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Germany</td>\n",
       "      <td>50.0</td>\n",
       "      <td>83000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>France</td>\n",
       "      <td>37.0</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country   Age   Salary Purchased\n",
       "0   France  44.0  72000.0        No\n",
       "1    Spain  27.0  48000.0       Yes\n",
       "2  Germany  30.0  54000.0        No\n",
       "3    Spain  38.0  61000.0        No\n",
       "4  Germany  40.0      NaN       Yes\n",
       "5   France  35.0  58000.0       Yes\n",
       "6    Spain   NaN  52000.0        No\n",
       "7   France  48.0  79000.0       Yes\n",
       "8  Germany  50.0  83000.0        No\n",
       "9   France  37.0  67000.0       Yes"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = pd.read_csv('data/Data.csv')\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([['France', 44.0, 72000.0],\n",
       "        ['Spain', 27.0, 48000.0],\n",
       "        ['Germany', 30.0, 54000.0],\n",
       "        ['Spain', 38.0, 61000.0],\n",
       "        ['Germany', 40.0, nan],\n",
       "        ['France', 35.0, 58000.0],\n",
       "        ['Spain', nan, 52000.0],\n",
       "        ['France', 48.0, 79000.0],\n",
       "        ['Germany', 50.0, 83000.0],\n",
       "        ['France', 37.0, 67000.0]], dtype=object),\n",
       " array(['No', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes'],\n",
       "       dtype=object))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separando o dataset em variáveis dependentes e independetes!\n",
    "# X = Variáveis Independentes\n",
    "# Y = Variáveis Dependentes (pensar no modelo de regressão linear)\n",
    "\n",
    "x = dt.iloc[:, :-1].values\n",
    "y = dt.iloc[:, -1].values\n",
    "\n",
    "x,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treating missing data\n",
    "\n",
    "In this particular case, I will be using the scikit-learn library to populate the missing data with the overall mean of the data.\n",
    "\n",
    "In cases of very large databases where the loss will be irrelevant, we can remove this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['France', 44.0, 72000.0],\n",
       "       ['Spain', 27.0, 48000.0],\n",
       "       ['Germany', 30.0, 54000.0],\n",
       "       ['Spain', 38.0, 61000.0],\n",
       "       ['Germany', 40.0, 63777.77777777778],\n",
       "       ['France', 35.0, 58000.0],\n",
       "       ['Spain', 38.77777777777778, 52000.0],\n",
       "       ['France', 48.0, 79000.0],\n",
       "       ['Germany', 50.0, 83000.0],\n",
       "       ['France', 37.0, 67000.0]], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean') # SipleImputer é como uma classe (OOP)\n",
    "imp.fit(x[:, 1:3]) # Ajustando a média dos valores faltantes OBVIAMENTE SÓ VAI NUMÉRICO\n",
    "x[:, 1:3] = imp.transform(x[:, 1:3]) # Transformando os valores faltantes\n",
    "\n",
    "x "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'Encoding Categorical Data'\n",
    "We will perform 'hot encoding' to separate the 'Country' column into three different columns (since there are 3 different groups/categories).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0, 0.0, 0.0, 44.0, 72000.0],\n",
       "       [0.0, 0.0, 1.0, 27.0, 48000.0],\n",
       "       [0.0, 1.0, 0.0, 30.0, 54000.0],\n",
       "       [0.0, 0.0, 1.0, 38.0, 61000.0],\n",
       "       [0.0, 1.0, 0.0, 40.0, 63777.77777777778],\n",
       "       [1.0, 0.0, 0.0, 35.0, 58000.0],\n",
       "       [0.0, 0.0, 1.0, 38.77777777777778, 52000.0],\n",
       "       [1.0, 0.0, 0.0, 48.0, 79000.0],\n",
       "       [0.0, 1.0, 0.0, 50.0, 83000.0],\n",
       "       [1.0, 0.0, 0.0, 37.0, 67000.0]], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\n",
    "x = np.array(ct.fit_transform(x)) # NÃO ESQUECER DO NP! POIS SE NÃO, NÃO RETORNA UMA ARRAY NUMPY ESTRAGANDO TUDO PARA USO\n",
    "\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding the Dependent Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 1, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.0, 0.0, 1.0, 38.77777777777778, 52000.0],\n",
       "        [0.0, 1.0, 0.0, 40.0, 63777.77777777778],\n",
       "        [1.0, 0.0, 0.0, 44.0, 72000.0],\n",
       "        [0.0, 0.0, 1.0, 38.0, 61000.0],\n",
       "        [0.0, 0.0, 1.0, 27.0, 48000.0],\n",
       "        [1.0, 0.0, 0.0, 48.0, 79000.0],\n",
       "        [0.0, 1.0, 0.0, 50.0, 83000.0],\n",
       "        [1.0, 0.0, 0.0, 35.0, 58000.0]], dtype=object),\n",
       " array([[0.0, 1.0, 0.0, 30.0, 54000.0],\n",
       "        [1.0, 0.0, 0.0, 37.0, 67000.0]], dtype=object),\n",
       " array([0, 1, 0, 0, 1, 1, 0, 1]),\n",
       " array([0, 1]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state=1)\n",
    "\n",
    "x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Scaling (Escalonamento de características/ Normalização de Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Não é necessário fazer o Feature Scaling para a Regressão Linear Múltipla, pois a biblioteca faz isso automaticamente!\n",
    "# - Ou seja não é todo modelo que usa feature scaling, mas é bom fazer para garantir que o modelo não seja prejudicado por isso!\n",
    "\n",
    "# Lembrando\n",
    "# normalização : recomendado quando tenho uma distribuição normal em maior parte das minhas caracterustucas\n",
    "# padronização : recomendado todo tempo, é uam boa prática, pois não sabemos a distribuição dos dados\n",
    "\n",
    "# padronização é sempre o mais recomendado\n",
    "# Só aplicar feature scalling nas características necessárias! Deixar as dummy variáveis intactas para matner interpretabilidade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.0, 0.0, 1.0, -0.19159184384578545, -1.0781259408412425],\n",
       "        [0.0, 1.0, 0.0, -0.014117293757057777, -0.07013167641635372],\n",
       "        [1.0, 0.0, 0.0, 0.566708506533324, 0.633562432710455],\n",
       "        [0.0, 0.0, 1.0, -0.30453019390224867, -0.30786617274297867],\n",
       "        [0.0, 0.0, 1.0, -1.9018011447007988, -1.420463615551582],\n",
       "        [1.0, 0.0, 0.0, 1.1475343068237058, 1.232653363453549],\n",
       "        [0.0, 1.0, 0.0, 1.4379472069688968, 1.5749910381638885],\n",
       "        [1.0, 0.0, 0.0, -0.7401495441200351, -0.5646194287757332]],\n",
       "       dtype=object),\n",
       " array([[0.0, 1.0, 0.0, -1.4661817944830124, -0.9069571034860727],\n",
       "        [1.0, 0.0, 0.0, -0.44973664397484414, 0.2056403393225306]],\n",
       "       dtype=object))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "x_train[:, 3:] = sc.fit_transform(x_train[:, 3:])\n",
    "x_test[:, 3:] = sc.transform(x_test[:, 3:]) # Não é necessário dar fit no x_test, pois já foi feito no x_train\n",
    "\n",
    "x_train, x_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
